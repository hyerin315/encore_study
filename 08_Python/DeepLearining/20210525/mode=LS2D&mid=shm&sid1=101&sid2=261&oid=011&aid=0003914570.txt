[자체 개발 '하이퍼클로바' 선봬]머스크 GPT-3보다 성능 탁월한국어 기반 'AI 주권' 확보도검색·쇼핑 등 서비스 접목 계획정석근 네이버 클로바 CIC(사내독립기업) 대표가 25일 '네이버 AI 나우' 컨퍼런스에서 처음 공개된 초거대(Hyperscale) AI '하이퍼클로바(HyperCLOVA)'를 소개하고 있다. /사진 제공=네이버[서울경제] “왜 바흐를 ‘음악의 아버지'라고 부르니?”(인간)“바흐 음악에서 풍기는 분위기가 마치 아버지처럼 온화하면서도 무게감 있고 굳건한 인상을 풍겨서 그렇게 불러왔어요.”(하이퍼클로바)25일 네이버가 공개한 초거대(Hyperscale) 인공지능(AI) ‘하이퍼클로바(HyperCLOVA)’는 인간의 질문에 이렇게 답했다. 성낙호 네이버 클로바 CIC(사내독립기업) 책임리더는 이날 프리젠테이션에서 “보통 AI가 딱딱하고 기계적일 것으로 생각하지만 하이퍼클로바는 사람처럼 맥락을 이해하고 공감하는 대화를 할 수 있다"며 “사용자의 만족도까지 인지해 대화 속 다양한 디테일을 놓치지 않는다”고 설명했다.하이퍼클로바는 네이버가 자체 개발한 초거대 AI다. 현재 LG전자, SK텔레콤, KT 등 국내 대기업들이 초거대 AI 개발에 나서고 있지만 상용화 단계까지 끌어 올려 완성된 모델을 내놓은 것은 네이버가 처음이다. 초거대 AI는 그래픽장치(GPU), 서버 등 컴퓨팅 리소스와 처리 가능한 데이터량에서 기존 AI와 차원이 다르다는 평가를 받는다. 가장 앞서가는 초거대 AI로 꼽히는 ‘GPT-3’는 AI에서 시냅스 역할을 하는 파라미터가 1,750억 개에 이른다. 지난 2019년 출시된 GPT-3의 이전 버전인 GPT-2의 파라미터가 15억 개였던 점을 감안하면 2년 사이 100배 가량 성능이 향상됐다. 파라미터가 많으면 많을 수록 AI는 더 복잡하고 많은 문제를 빠른 시간에 해결할 수 있다. 네이버에 따르면 하이퍼클로바는 GPT-3를 뛰어넘는 2,040억 파라미터 규모의 초거대 AI다. 또 GPT-3보다 한국어 데이터를 6,500배 이상 학습해 영어가 아닌 한국어에 최적화됐다. 학습 데이터 중 한국어 비중이 97%에 달한다. 하이퍼클러바가 학습한 한국어 데이터는 약 5,600억 토큰(말뭉치)에 달한다. 이는 뉴스 50년치, 네이버 블로그 9년 치와 비슷한 용량이다. 성 책임리더는 “인간은 문서 등을 보고 학습할 때 글만 보고 이해하지 않는다”며 "앞으로 하이퍼클로바의 학습 영역과 활용 분야를 글 뿐만 아니라 그림, 음성, 비디오 등 다양한 모달리티(양식)로 확장할 것"이라고 말했다.네이버는 지난해 10월 한국어에 최적화한 모델을 만들어 AI 주권을 확보한다는 목표를 세우고 초거대 AI 개발에 착수했다. 국내 기업 최초로 700페타플롭(PF·1페타플롭은 1초당 1,000조 번의 연산 처리가 가능한 수준) 성능의 슈퍼컴퓨터를 적용해 올 1분기 개발을 마쳤다. 현재 하이퍼클로바는 사용자들이 네이버에서 검색할 때 오탈자를 자동 수정하는 등 검색 엔진 일부에 실제로 활용되고 있다. 네이버는 앞으로 검색 외에도 쇼핑, 지도 등 10개 이상 서비스에 하이퍼클로바를 도입해 차별화한 서비스를 제공할 계획이다. 정석근 네이버 클로바 대표는 “더 짧은 시간과 더 적은 리소스를 사용해 상상만 했거나 상상조차 하지 못했던 일들이 가능해지는 새로운 AI의 시대가 열리고 있다”며 “하이퍼클로바는 AI 기술이 필요한 모두에게 새로운 경험을 제공할 것”이라고 말했다./ 